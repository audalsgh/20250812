# 4ì¸ 1ì¡°ë¡œ ë¡œë³´í”Œë¡œìš° + SegFormer í”„ë¡œì íŠ¸

## ë¡œë³´í”Œë¡œìš° ë‚´ì—ì„œ í•œì¼
[ì‚¬ìš©í•œ AI HUB ì´ë¯¸ì§€ ìë£Œ ë§í¬](https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=1&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EB%8F%84%EB%A1%9C&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&srchDataRealmCode=REALM003&aihubDataSe=data&dataSetSn=71625)

1. ì¡°ì›ë¶„ë“¤ê³¼ ë¼ë²¨ë§ ì‘ì—…. 800ì¥ ëª©í‘œ.
<img width="1457" height="910" alt="image" src="https://github.com/user-attachments/assets/4b61ed5d-5f94-4db3-80f1-c8f17146a470" />

2. ë¼ë²¨ë§ ì™„ë£Œ í›„, ë°ì´í„°ì…‹ì„ coco ì˜µì…˜ìœ¼ë¡œ ë‹¤ìš´ë°›ê¸°.
<img width="1462" height="897" alt="image" src="https://github.com/user-attachments/assets/11b4dbe3-6e8a-4a99-9122-6c7586dc525a" />

3. í”„ë¡œì íŠ¸ íƒ€ì…ì´ segmentation ì¸ í”„ë¡œì íŠ¸ë¥¼ ìƒˆë¡œ ë§Œë“¤ê¸°.
<img width="1306" height="404" alt="image" src="https://github.com/user-attachments/assets/e1ed2284-e3f2-4998-a524-1b677e71c8a5" />

4. ìƒˆë¡œë§Œë“  segmentation í”„ë¡œì íŠ¸ì— 800ì¥ì§œë¦¬ coco ë°ì´í„°ì…‹ zipíŒŒì¼ì„ ì—…ë¡œë“œí•˜ê¸°.
<img width="2505" height="804" alt="image" src="https://github.com/user-attachments/assets/ee39bb48-0eaf-43a7-99e8-a5b1181e5532" />

5. create new versionì„ ë§Œë“¤ê³ , download datasetì„ ëˆŒëŸ¬ì„œ Semantic Segmentation Masks ì˜µì…˜ìœ¼ë¡œ ë‹¤ìš´ë°›ê¸°.
<img width="1445" height="753" alt="image" src="https://github.com/user-attachments/assets/e1550101-168c-4d15-af3d-ebdd411d92d6" />

6. ì´ì œ ì½”ë©ì´ë‚˜ runpodë¡œ ë„˜ì–´ê°€ì„œ, segformer ì „ì´í•™ìŠµ ì½”ë“œ ì‹¤ìŠµí•´ë³´ê¸°. (gpt ì´ìš©)
<img width="1702" height="940" alt="image" src="https://github.com/user-attachments/assets/b51dcda2-1a31-45dd-8489-b26a432f0bfd" />

- mask-semantic.zip íŒŒì¼ ì—…ë¡œë“œí•˜ê³ , í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í•˜ëŠ” ì²«ë²ˆì¬ ì…€ì—ì„œ ì˜¤ë¥˜ê°€ìˆì§€ë§Œ ì‘ë™ì€ í•˜ë¯€ë¡œ ë„˜ì–´ê°„ë‹¤.
- ëª¨ë“  ì „ì´í•™ìŠµì´ ê·¸ë ‡ë“¯, 20 ì—í¬í¬ í•˜ëŠ”ë°ì— 25ë¶„ ì´ìƒ ì†Œìš”ë˜ì—ˆë‹¤.

7. runpodì—ì„œ ì „ì´í•™ìŠµê¹Œì§€ ìƒˆë¡œ ë§ˆì¹˜ê³ , ê²°ê³¼ì˜ìƒê¹Œì§€ ì–»ì–´ë³´ê¸°. (gpt ì´ìš©)

### ì½”ë©ìš© ì „ì´í•™ìŠµ ì½”ë“œ. ì•„ê¹Œ ë¡œë³´í”Œë¡œìš°ì—ì„œ ë‹¤ìš´ë°›ì€ mask.zipíŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼í•¨.
```python
# ========================
# 0) í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ========================
!pip install -q "transformers>=4.44,<5" accelerate evaluate opencv-python-headless pillow

# ========================
# 1) Roboflow ZIP ì—…ë¡œë“œ
# ========================
from google.colab import files
up = files.upload()  # Roboflowì—ì„œ ë°›ì€ dataset.zip ì„ íƒ
ZIP_PATH = "/content/" + list(up.keys())[0]

# ========================
# 2) ì••ì¶• í•´ì œ
# ========================
import os, zipfile, shutil

EXTRACT_DIR = "/content/ds_rf"
if os.path.isdir(EXTRACT_DIR):
    shutil.rmtree(EXTRACT_DIR)
os.makedirs(EXTRACT_DIR, exist_ok=True)

with zipfile.ZipFile(ZIP_PATH, "r") as z:
    z.extractall(EXTRACT_DIR)

print("unzipped to", EXTRACT_DIR, "->", os.listdir(EXTRACT_DIR))

# ========================
# 3) ë°ì´í„° êµ¬ì¡° íŒŒì•…
# ========================
def find_split_dir(root, names=("train","valid","val","test")):
    found = {}
    for n in names:
        p = os.path.join(root, n)
        if os.path.isdir(p):
            found["valid" if n in ("valid","val") else n] = p
    return found

splits = find_split_dir(EXTRACT_DIR)
if not splits:
    raise RuntimeError("train/valid/test í´ë”ë¥¼ ì°¾ì§€ ëª»í•¨. ZIP ë‚´ìš© í™•ì¸")

# ========================
# 4) í•™ìŠµ í´ë˜ìŠ¤ ì„¤ì •
# ========================
COLLAPSE_TO_BINARY = True  # Trueë©´ ëª¨ë“  non-zero â†’ 'lane(1)'
if COLLAPSE_TO_BINARY:
    CLASS_NAMES = ["background", "lane"]
else:
    CLASS_NAMES = ["background", "lane", "lane-dot", "lane-mid", "lane_crosswalk"]

id2label = {i: n for i, n in enumerate(CLASS_NAMES)}
label2id = {n: i for i, n in id2label.items()}
NUM_LABELS = len(CLASS_NAMES)

# === íŒ¨ì¹˜: RFSegFolderë¥¼ ë” ê´€ëŒ€í•œ ë²„ì „ìœ¼ë¡œ ì¬ì •ì˜ ===
import os, glob, re
import numpy as np
from PIL import Image
from torch.utils.data import Dataset

# ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ íŒŒì¼ëª… ë§¤ì¹­ì„ ìœ„í•´ ë’¤ì— ë¶™ëŠ” ì ‘ë¯¸ì–´ë“¤ì„ ì œê±°
_SUFFIX_RE = re.compile(r'(_|-)(mask|masks|label|labels|seg|segment|segmentation)$', re.I)

def _stem_no_suffix(path):
    s = os.path.splitext(os.path.basename(path))[0]
    s = _SUFFIX_RE.sub('', s)   # ..._mask, -labels ë“± ì œê±°
    return s

def _is_img(name):
    return name.lower().endswith((".jpg",".jpeg",".png",".bmp",".tif",".tiff"))

class RFSegFolder(Dataset):
    def __init__(self, split_dir, processor):
        # 1) ì´ë¯¸ì§€ í´ë” íƒìƒ‰: 'images/'ê°€ ìˆìœ¼ë©´ ê±°ê¸°, ì—†ìœ¼ë©´ split ë£¨íŠ¸ì—ì„œ ë°”ë¡œ ì°¾ê¸°
        img_cands = [os.path.join(split_dir, "images"), split_dir]
        self.img_dir = None
        for d in img_cands:
            if os.path.isdir(d) and any(_is_img(f) for f in os.listdir(d)):
                self.img_dir = d
                break
        if self.img_dir is None:
            raise RuntimeError(f"No images found in {split_dir}")

        # 2) ë§ˆìŠ¤í¬ í´ë” í›„ë³´: labels/masks/annotations/â€¦ ì—†ìœ¼ë©´ split ë£¨íŠ¸ê¹Œì§€ í¬í•¨
        mask_cands = ["masks","labels","annotations","masks_png","labels_png","mask","Labels","Masks"]
        self.mask_dirs = [os.path.join(split_dir, c) for c in mask_cands if os.path.isdir(os.path.join(split_dir, c))]
        if not self.mask_dirs:
            # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: split ë””ë ‰í† ë¦¬ ì•ˆì—ì„œ PNGê°€ ìˆëŠ” ëª¨ë“  í´ë”ë¥¼ ìŠ¤ìº”(ì´ë¯¸ì§€ í´ë” ì œì™¸)
            self.mask_dirs = []
            for root, dirs, files in os.walk(split_dir):
                if os.path.abspath(root) == os.path.abspath(self.img_dir):
                    continue
                if any(f.lower().endswith(".png") for f in files):
                    self.mask_dirs.append(root)
            if not self.mask_dirs:
                # ì •ë§ ì—†ìœ¼ë©´ ë£¨íŠ¸ë„ í›„ë³´ì— í¬í•¨(ì•„ì£¼ ë“œë¬¸ ì¼€ì´ìŠ¤)
                self.mask_dirs = [split_dir]

        self.processor = processor

        # 3) ë§ˆìŠ¤í¬ ì¸ë±ìŠ¤ êµ¬ì¶• (ë™ì¼ stem ë§¤ì¹­)
        mask_map = {}
        for md in self.mask_dirs:
            for p in glob.glob(os.path.join(md, "*.png")):
                mask_map[_stem_no_suffix(p)] = p

        # 4) ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ í˜ì–´ ë§Œë“¤ê¸°
        self.items = []
        for ip in sorted(glob.glob(os.path.join(self.img_dir, "*.*"))):
            if not _is_img(ip):
                continue
            st = _stem_no_suffix(ip)
            mp = mask_map.get(st)
            if mp and os.path.exists(mp):
                self.items.append((ip, mp))

        if not self.items:
            # ë””ë²„ê¹… ë„ì›€: í´ë” ì•ˆì— ë­ê°€ ìˆëŠ”ì§€ ì¡°ê¸ˆ ì°ì–´ì¤Œ
            print("[DEBUG] img_dir:", self.img_dir)
            print("[DEBUG] mask_dirs:", self.mask_dirs[:3], "â€¦", f"({sum(len(glob.glob(os.path.join(d,'*.png'))) for d in self.mask_dirs)} masks png)")
            raise RuntimeError(f"No (image,mask) pairs in {split_dir}. "
                               f"ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ íŒŒì¼ëª…ì´ ì„œë¡œ ë§¤ì¹­ë˜ëŠ”ì§€(ì˜ˆ: abc.jpg â†” abc_mask.png) í™•ì¸í•´ì£¼ì„¸ìš”.")

    def __len__(self):
        return len(self.items)

    def __getitem__(self, idx):
        ip, mp = self.items[idx]
        image = Image.open(ip).convert("RGB")
        # íŒ”ë ˆíŠ¸/ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ëª¨ë‘ ì§€ì›: 0=ë°°ê²½, 1+=ì „ë¶€ ì°¨ì„ ìœ¼ë¡œ ë­‰ì¹˜ê¸°(ì´ì§„)
        m = np.array(Image.open(mp).convert("L"), dtype=np.uint8)
        m = (m > 0).astype(np.uint8)  # ì´ì§„ ì„¸íŒ… (ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ì“°ë ¤ë©´ ì—¬ê¸° ë¡œì§ ë°”ê¿”ë„ ë¨)
        enc = processor(images=image, segmentation_maps=m, return_tensors="pt")
        return {k: v.squeeze(0) for k, v in enc.items()}

# ========================
# 5) í”„ë¡œì„¸ì„œ/ëª¨ë¸ ë¡œë“œ
# ========================
from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
import torch

CKPT = "nvidia/segformer-b0-finetuned-ade-512-512"

processor = SegformerImageProcessor.from_pretrained(
    CKPT,
    reduce_labels=False  # ë¼ë²¨ ì¤„ì„ ë¹„í™œì„±í™”(ìš°ë¦¬ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ìœ ì§€)
)

model = SegformerForSemanticSegmentation.from_pretrained(
    CKPT,
    num_labels=NUM_LABELS,   # ìœ„ì—ì„œ ë§Œë“  NUM_LABELS ì‚¬ìš©
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True  # í´ë¼ìŠ¤ ìˆ˜ê°€ ë‹¬ë¼ ìƒê¸°ëŠ” shape mismatch í—ˆìš©
)

# ========================
# 6) ë°ì´í„°ì…‹ ìƒì„±
# ========================
# splitsëŠ” ì´ë¯¸ ìœ„ì—ì„œ ë§Œë“¤ì–´ ë‘” dict: {'train': ..., 'valid': ..., 'test': ...} ì¤‘ ì¼ë¶€
train_dir = splits.get("train")
valid_dir = splits.get("valid") or splits.get("val") or train_dir  # valid ì—†ìœ¼ë©´ train ì¬ì‚¬ìš©

if train_dir is None:
    raise RuntimeError("train í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ZIP êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

train_ds = RFSegFolder(train_dir, processor)  # ì´ì§„ ì„¸íŒ…ì€ í´ë˜ìŠ¤ ë‚´ë¶€ì—ì„œ m>0 â†’ 1ë¡œ ì²˜ë¦¬
val_ds   = RFSegFolder(valid_dir, processor)
print(f"âœ… Dataset ready: train={len(train_ds)}, valid={len(val_ds)}")

# ========================
# 7) í•™ìŠµ + ì €ì¥ + ë‹¤ìš´ë¡œë“œ
# ========================
from transformers import TrainingArguments, Trainer
import numpy as np, evaluate, torch, os, shutil, zipfile
from google.colab import files

metric = evaluate.load("mean_iou")

def _to_py(o):
    import numpy as np
    if isinstance(o, np.ndarray):
        return o.tolist()
    if isinstance(o, (np.floating, np.integer)):
        return o.item()
    return o

def compute_metrics(eval_pred):
    logits, labels = eval_pred  # logits: (N, C, h, w), labels: (N, H, W)
    if isinstance(logits, tuple):
        logits = logits[0]
    lt = torch.from_numpy(logits)
    yt = torch.from_numpy(labels)

    # ë¼ë²¨ í¬ê¸°ì— ë§ì¶° ì—…ìƒ˜í”Œ(í¬ê¸° ë¶ˆì¼ì¹˜ ë°©ì§€)
    lt_up = torch.nn.functional.interpolate(
        lt, size=yt.shape[-2:], mode="bilinear", align_corners=False
    )
    preds = lt_up.argmax(dim=1).cpu().numpy()

    res = metric.compute(
        predictions=preds,
        references=labels,
        num_labels=NUM_LABELS,
        ignore_index=255,
        reduce_labels=False,
    )
    return {k: _to_py(v) for k, v in res.items()}

args = TrainingArguments(
    output_dir="segformer-lane",
    learning_rate=5e-5,
    num_train_epochs=20,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    eval_strategy="epoch"
    save_strategy="epoch",
    fp16=torch.cuda.is_available(),
    logging_steps=50,
    load_best_model_at_end=True,
    metric_for_best_model="mean_iou",
    greater_is_better=True,
    report_to="none",
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    compute_metrics=compute_metrics,
)

# í•™ìŠµ
trainer.train()

# ë² ìŠ¤íŠ¸ ì €ì¥
BEST_DIR = "segformer-lane/best"
os.makedirs(BEST_DIR, exist_ok=True)
trainer.save_model(BEST_DIR)            # ëª¨ë¸ ê°€ì¤‘ì¹˜/êµ¬ì„±
processor.save_pretrained(BEST_DIR)     # í”„ë¡œì„¸ì„œ

print("âœ… Saved best to:", BEST_DIR)

# ì•„í‹°íŒ©íŠ¸ ì••ì¶•(zip) í›„ ë‹¤ìš´ë¡œë“œ(í•„ìš”í•œ ê²ƒë§Œ ë¬¶ìŒ)
ZIP_OUT = "segformer_lane_best.zip"
with zipfile.ZipFile(ZIP_OUT, "w", zipfile.ZIP_DEFLATED) as z:
    # í•µì‹¬ íŒŒì¼ë“¤ë§Œ ì„ íƒ ì €ì¥
    for fname in [
        "config.json", "preprocessor_config.json", "model.safetensors", "pytorch_model.bin"
    ]:
        p = os.path.join(BEST_DIR, fname)
        if os.path.exists(p):
            z.write(p, arcname=os.path.join("best", fname))
    # trainer args/ë¡œê·¸ ë“± ë©”íƒ€(ì„ íƒ)
    for extra in ["trainer_state.json", "trainer_config.json", "all_results.json"]:
        p = os.path.join("segformer-lane", extra)
        if os.path.exists(p):
            z.write(p, arcname=os.path.join("run_meta", extra))

print("ğŸ“¦ Zip created:", ZIP_OUT)

# ë‹¤ìš´ë¡œë“œ íŠ¸ë¦¬ê±°
files.download(ZIP_OUT)  # Colabì—ì„œ íŒŒì¼ ë‹¤ìš´
```
