{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOM8n48hyX53yCnfe4c8NgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audalsgh/20250812/blob/main/0812_Roboflow_Segformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 첫 코드에서 설치와, Semantic Segmentation Masks zip파일을 업로드했기에 오류가 떠도 일단 남겨두었다."
      ],
      "metadata": {
        "id": "SBpqCHWOUsdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) 설치\n",
        "!pip -q install transformers accelerate evaluate opencv-python-headless pillow\n",
        "\n",
        "# 1) ZIP 업로드 (수동 업로드 창이 뜹니다)\n",
        "from google.colab import files\n",
        "up = files.upload()  # 방금 받은 Roboflow ZIP 선택\n",
        "ZIP_PATH = \"/content/\" + list(up.keys())[0]\n",
        "\n",
        "# 2) 압축 풀기\n",
        "import os, zipfile, glob, shutil, re\n",
        "EXTRACT_DIR = \"/content/ds_rf\"\n",
        "if os.path.isdir(EXTRACT_DIR): shutil.rmtree(EXTRACT_DIR)\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "with zipfile.ZipFile(ZIP_PATH, \"r\") as z: z.extractall(EXTRACT_DIR)\n",
        "print(\"unzipped to\", EXTRACT_DIR, \"->\", os.listdir(EXTRACT_DIR))\n",
        "\n",
        "# 3) 데이터 구조 파악 (train/valid/test)\n",
        "def find_split_dir(root, names=(\"train\",\"valid\",\"val\",\"test\")):\n",
        "    found={}\n",
        "    for n in names:\n",
        "        p=os.path.join(root,n)\n",
        "        if os.path.isdir(p): found[\"valid\" if n in (\"valid\",\"val\") else n]=p\n",
        "    return found\n",
        "splits = find_split_dir(EXTRACT_DIR)\n",
        "if not splits: raise RuntimeError(\"train/valid/test 폴더를 찾지 못함. ZIP 내용 확인\")\n",
        "\n",
        "# 4) 학습 설정\n",
        "COLLAPSE_TO_BINARY = True  # True: 모든 non-zero를 'lane(1)'로 합치기\n",
        "if COLLAPSE_TO_BINARY:\n",
        "    CLASS_NAMES = [\"background\",\"lane\"]\n",
        "else:\n",
        "    # 예) 멀티클래스: background + lane 계열\n",
        "    CLASS_NAMES = [\"background\",\"lane\",\"lane-dot\",\"lane-mid\",\"lane_crosswalk\"]\n",
        "\n",
        "id2label = {i:n for i,n in enumerate(CLASS_NAMES)}\n",
        "label2id = {n:i for i,n in id2label.items()}\n",
        "NUM_LABELS = len(CLASS_NAMES)\n",
        "\n",
        "# 5) 데이터셋 클래스 (Roboflow 'Semantic Segmentation Masks' 구조 자동 대응)\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import SegformerImageProcessor\n",
        "\n",
        "def normalize_stem(s):\n",
        "    s=os.path.splitext(os.path.basename(s))[0]\n",
        "    s=re.sub(r'(_mask|-mask)$','',s)\n",
        "    return s\n",
        "\n",
        "def index_mask_array(mask_img, collapse_to_binary=True):\n",
        "    # 팔레트 PNG/그레이스케일 모두 지원\n",
        "    m = np.array(mask_img.convert(\"L\"), dtype=np.uint8)\n",
        "    if collapse_to_binary:\n",
        "        m = (m>0).astype(np.uint8)  # 0/1\n",
        "    else:\n",
        "        # 0..K 인덱스 그대로 사용 (배경은 0이어야 함)\n",
        "        pass\n",
        "    return m\n",
        "\n",
        "class RFSegFolder(Dataset):\n",
        "    def __init__(self, split_dir, processor):\n",
        "        self.img_dir = os.path.join(split_dir, \"images\")\n",
        "        # 마스크 폴더 후보\n",
        "        cand = [\"masks\",\"labels\",\"annotations\",\"masks_png\",\"labels_png\"]\n",
        "        self.mask_dirs = [os.path.join(split_dir,c) for c in cand if os.path.isdir(os.path.join(split_dir,c))]\n",
        "        if not self.mask_dirs:\n",
        "            # 일부 버전에선 images와 같은 폴더에 있을 수 있음(드물지만)\n",
        "            self.mask_dirs = [split_dir]\n",
        "        self.processor = processor\n",
        "\n",
        "        # 마스크 인덱스 구축\n",
        "        mask_map = {}\n",
        "        for md in self.mask_dirs:\n",
        "            for p in glob.glob(os.path.join(md, \"*.png\")):\n",
        "                mask_map[normalize_stem(p)] = p\n",
        "\n",
        "        # 이미지-마스크 페어 만들기\n",
        "        self.items=[]\n",
        "        for ip in sorted(glob.glob(os.path.join(self.img_dir, \"*.*\"))):\n",
        "            st = normalize_stem(ip)\n",
        "            mp = mask_map.get(st)\n",
        "            if mp and os.path.exists(mp):\n",
        "                self.items.append((ip, mp))\n",
        "        if not self.items:\n",
        "            raise RuntimeError(f\"No (image,mask) pairs in {split_dir}. 마스크 폴더명이 'masks/labels/annotations' 중 하나인지 확인\")\n",
        "\n",
        "    def __len__(self): return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ip, mp = self.items[idx]\n",
        "        image = Image.open(ip).convert(\"RGB\")\n",
        "        mask  = Image.open(mp)\n",
        "        mask  = index_mask_array(mask, COLLAPSE_TO_BINARY)\n",
        "        enc = self.processor(images=image, segmentation_maps=mask, return_tensors=\"pt\")\n",
        "        return {k: v.squeeze(0) for k,v in enc.items()}\n",
        "\n",
        "# 6) 프로세서/모델\n",
        "from transformers import SegformerForSemanticSegmentation\n",
        "import torch, evaluate\n",
        "\n",
        "CKPT = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
        "processor = SegformerImageProcessor.from_pretrained(CKPT, reduce_labels=False)\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    CKPT,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# 7) 데이터 로더 구성\n",
        "train_dir = splits.get(\"train\")\n",
        "valid_dir = splits.get(\"valid\") or splits.get(\"val\") or train_dir  # valid 없으면 train 재사용(데모용)\n",
        "train_ds = RFSegFolder(train_dir, processor)\n",
        "val_ds   = RFSegFolder(valid_dir, processor)\n",
        "\n",
        "# 8) 학습\n",
        "from transformers import TrainingArguments, Trainer\n",
        "metric = evaluate.load(\"mean_iou\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return metric.compute(\n",
        "        predictions=preds, references=labels,\n",
        "        num_labels=NUM_LABELS, ignore_index=255, reduce_labels=False\n",
        "    )\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"segformer-lane\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"mean_iou\",\n",
        "    greater_is_better=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
        "trainer.train()\n",
        "\n",
        "# 9) 저장\n",
        "trainer.save_model(\"segformer-lane/best\")\n",
        "processor.save_pretrained(\"segformer-lane/best\")\n",
        "print(\"✅ Saved to segformer-lane/best\")"
      ],
      "metadata": {
        "id": "evWfWBlaUrWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 패치: RFSegFolder를 더 관대한 버전으로 재정의 ===\n",
        "import os, glob, re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 이미지/마스크 파일명 매칭을 위해 뒤에 붙는 접미어들을 제거\n",
        "_SUFFIX_RE = re.compile(r'(_|-)(mask|masks|label|labels|seg|segment|segmentation)$', re.I)\n",
        "\n",
        "def _stem_no_suffix(path):\n",
        "    s = os.path.splitext(os.path.basename(path))[0]\n",
        "    s = _SUFFIX_RE.sub('', s)   # ..._mask, -labels 등 제거\n",
        "    return s\n",
        "\n",
        "def _is_img(name):\n",
        "    return name.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"))\n",
        "\n",
        "class RFSegFolder(Dataset):\n",
        "    def __init__(self, split_dir, processor):\n",
        "        # 1) 이미지 폴더 탐색: 'images/'가 있으면 거기, 없으면 split 루트에서 바로 찾기\n",
        "        img_cands = [os.path.join(split_dir, \"images\"), split_dir]\n",
        "        self.img_dir = None\n",
        "        for d in img_cands:\n",
        "            if os.path.isdir(d) and any(_is_img(f) for f in os.listdir(d)):\n",
        "                self.img_dir = d\n",
        "                break\n",
        "        if self.img_dir is None:\n",
        "            raise RuntimeError(f\"No images found in {split_dir}\")\n",
        "\n",
        "        # 2) 마스크 폴더 후보: labels/masks/annotations/… 없으면 split 루트까지 포함\n",
        "        mask_cands = [\"masks\",\"labels\",\"annotations\",\"masks_png\",\"labels_png\",\"mask\",\"Labels\",\"Masks\"]\n",
        "        self.mask_dirs = [os.path.join(split_dir, c) for c in mask_cands if os.path.isdir(os.path.join(split_dir, c))]\n",
        "        if not self.mask_dirs:\n",
        "            # 마지막 수단: split 디렉토리 안에서 PNG가 있는 모든 폴더를 스캔(이미지 폴더 제외)\n",
        "            self.mask_dirs = []\n",
        "            for root, dirs, files in os.walk(split_dir):\n",
        "                if os.path.abspath(root) == os.path.abspath(self.img_dir):\n",
        "                    continue\n",
        "                if any(f.lower().endswith(\".png\") for f in files):\n",
        "                    self.mask_dirs.append(root)\n",
        "            if not self.mask_dirs:\n",
        "                # 정말 없으면 루트도 후보에 포함(아주 드문 케이스)\n",
        "                self.mask_dirs = [split_dir]\n",
        "\n",
        "        self.processor = processor\n",
        "\n",
        "        # 3) 마스크 인덱스 구축 (동일 stem 매칭)\n",
        "        mask_map = {}\n",
        "        for md in self.mask_dirs:\n",
        "            for p in glob.glob(os.path.join(md, \"*.png\")):\n",
        "                mask_map[_stem_no_suffix(p)] = p\n",
        "\n",
        "        # 4) 이미지-마스크 페어 만들기\n",
        "        self.items = []\n",
        "        for ip in sorted(glob.glob(os.path.join(self.img_dir, \"*.*\"))):\n",
        "            if not _is_img(ip):\n",
        "                continue\n",
        "            st = _stem_no_suffix(ip)\n",
        "            mp = mask_map.get(st)\n",
        "            if mp and os.path.exists(mp):\n",
        "                self.items.append((ip, mp))\n",
        "\n",
        "        if not self.items:\n",
        "            # 디버깅 도움: 폴더 안에 뭐가 있는지 조금 찍어줌\n",
        "            print(\"[DEBUG] img_dir:\", self.img_dir)\n",
        "            print(\"[DEBUG] mask_dirs:\", self.mask_dirs[:3], \"…\", f\"({sum(len(glob.glob(os.path.join(d,'*.png'))) for d in self.mask_dirs)} masks png)\")\n",
        "            raise RuntimeError(f\"No (image,mask) pairs in {split_dir}. \"\n",
        "                               f\"이미지/마스크 파일명이 서로 매칭되는지(예: abc.jpg ↔ abc_mask.png) 확인해주세요.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ip, mp = self.items[idx]\n",
        "        image = Image.open(ip).convert(\"RGB\")\n",
        "        # 팔레트/그레이스케일 모두 지원: 0=배경, 1+=전부 차선으로 뭉치기(이진)\n",
        "        m = np.array(Image.open(mp).convert(\"L\"), dtype=np.uint8)\n",
        "        m = (m > 0).astype(np.uint8)  # 이진 세팅 (여러 클래스를 쓰려면 여기 로직 바꿔도 됨)\n",
        "        enc = processor(images=image, segmentation_maps=m, return_tensors=\"pt\")\n",
        "        return {k: v.squeeze(0) for k, v in enc.items()}"
      ],
      "metadata": {
        "id": "1ZliBXgkPJ3v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np, evaluate, torch\n",
        "\n",
        "metric = evaluate.load(\"mean_iou\")\n",
        "\n",
        "def _to_py(o):\n",
        "    if isinstance(o, np.ndarray):\n",
        "        return o.tolist()\n",
        "    if isinstance(o, (np.floating, np.integer)):\n",
        "        return o.item()\n",
        "    return o\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred  # logits: (N, C, h, w), labels: (N, H, W)\n",
        "    if isinstance(logits, tuple):\n",
        "        logits = logits[0]\n",
        "    lt = torch.from_numpy(logits)\n",
        "    yt = torch.from_numpy(labels)\n",
        "\n",
        "    # 라벨 크기에 맞춰 업샘플(크기 불일치 방지)\n",
        "    lt_up = torch.nn.functional.interpolate(\n",
        "        lt, size=yt.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "    )\n",
        "    preds = lt_up.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    res = metric.compute(\n",
        "        predictions=preds,\n",
        "        references=labels,\n",
        "        num_labels=getattr(model.config, \"num_labels\", 2),\n",
        "        ignore_index=255,\n",
        "        reduce_labels=False,\n",
        "    )\n",
        "    # ✅ JSON 직렬화 가능하도록 변환\n",
        "    return {k: _to_py(v) for k, v in res.items()}\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"segformer-lane\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"mean_iou\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()  # 체크포인트에서 이어하려면: trainer.train(resume_from_checkpoint=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8pM9q2MFRGaj",
        "outputId": "b006a8a2-5dbb-44a3-a7b0-e17e4962fce9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7120' max='7120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7120/7120 22:50, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mean Iou</th>\n",
              "      <th>Mean Accuracy</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>Per Category Iou</th>\n",
              "      <th>Per Category Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.041800</td>\n",
              "      <td>0.051805</td>\n",
              "      <td>0.829753</td>\n",
              "      <td>0.891799</td>\n",
              "      <td>0.978775</td>\n",
              "      <td>[0.977764526246168, 0.6817407377445032]</td>\n",
              "      <td>[0.9900312565575472, 0.79356707346073]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.051026</td>\n",
              "      <td>0.824263</td>\n",
              "      <td>0.876652</td>\n",
              "      <td>0.978599</td>\n",
              "      <td>[0.9776227191937592, 0.670902560475457]</td>\n",
              "      <td>[0.9917922488130659, 0.7615108769059554]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.043500</td>\n",
              "      <td>0.049662</td>\n",
              "      <td>0.823929</td>\n",
              "      <td>0.867503</td>\n",
              "      <td>0.979051</td>\n",
              "      <td>[0.9781211282789524, 0.6697368534093936]</td>\n",
              "      <td>[0.9934862420854199, 0.7415196278928194]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.046568</td>\n",
              "      <td>0.840051</td>\n",
              "      <td>0.898403</td>\n",
              "      <td>0.980284</td>\n",
              "      <td>[0.9793298821908697, 0.7007721688383226]</td>\n",
              "      <td>[0.9908807389195879, 0.8059249888234679]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.048303</td>\n",
              "      <td>0.832564</td>\n",
              "      <td>0.879720</td>\n",
              "      <td>0.979911</td>\n",
              "      <td>[0.9789879666681581, 0.686140205392096]</td>\n",
              "      <td>[0.992876718980598, 0.7665626694314712]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.047084</td>\n",
              "      <td>0.840808</td>\n",
              "      <td>0.897480</td>\n",
              "      <td>0.980461</td>\n",
              "      <td>[0.9795181158565466, 0.702097482588834]</td>\n",
              "      <td>[0.991200067981712, 0.8037600707688503]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.046345</td>\n",
              "      <td>0.843238</td>\n",
              "      <td>0.896089</td>\n",
              "      <td>0.980948</td>\n",
              "      <td>[0.980032978899547, 0.7064439120770976]</td>\n",
              "      <td>[0.991930235502293, 0.800248261692555]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.045964</td>\n",
              "      <td>0.844460</td>\n",
              "      <td>0.902385</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>[0.9799282932035621, 0.7089910081630961]</td>\n",
              "      <td>[0.9910201707982706, 0.8137504637071844]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.029900</td>\n",
              "      <td>0.045453</td>\n",
              "      <td>0.845824</td>\n",
              "      <td>0.903432</td>\n",
              "      <td>0.981052</td>\n",
              "      <td>[0.9801225168152489, 0.7115263039997345]</td>\n",
              "      <td>[0.9910964768015298, 0.8157669954628035]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>0.046826</td>\n",
              "      <td>0.841864</td>\n",
              "      <td>0.887938</td>\n",
              "      <td>0.981101</td>\n",
              "      <td>[0.9802141813866447, 0.7035146665298759]</td>\n",
              "      <td>[0.9931578950410925, 0.7827187033320334]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.046642</td>\n",
              "      <td>0.846461</td>\n",
              "      <td>0.908422</td>\n",
              "      <td>0.980933</td>\n",
              "      <td>[0.979985463193942, 0.7129362748838419]</td>\n",
              "      <td>[0.9903170572242997, 0.8265269045286358]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.047275</td>\n",
              "      <td>0.844885</td>\n",
              "      <td>0.898325</td>\n",
              "      <td>0.981126</td>\n",
              "      <td>[0.9802137525782714, 0.7095556848886571]</td>\n",
              "      <td>[0.991841500869715, 0.8048092379983068]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>0.049390</td>\n",
              "      <td>0.844053</td>\n",
              "      <td>0.891700</td>\n",
              "      <td>0.981294</td>\n",
              "      <td>[0.9804066531620969, 0.7077000633553828]</td>\n",
              "      <td>[0.9928886273417127, 0.7905108864178977]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.046725</td>\n",
              "      <td>0.845412</td>\n",
              "      <td>0.896380</td>\n",
              "      <td>0.981306</td>\n",
              "      <td>[0.9804077951651607, 0.7104163043680133]</td>\n",
              "      <td>[0.9922967933558282, 0.8004632315872579]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.026200</td>\n",
              "      <td>0.047736</td>\n",
              "      <td>0.846620</td>\n",
              "      <td>0.898350</td>\n",
              "      <td>0.981421</td>\n",
              "      <td>[0.980523038092991, 0.7127171916342249]</td>\n",
              "      <td>[0.9921711196807634, 0.8045295868963483]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.026900</td>\n",
              "      <td>0.049956</td>\n",
              "      <td>0.843689</td>\n",
              "      <td>0.892050</td>\n",
              "      <td>0.981216</td>\n",
              "      <td>[0.9803237011800117, 0.7070539842262714]</td>\n",
              "      <td>[0.9927549762208527, 0.7913441325584271]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.028300</td>\n",
              "      <td>0.048467</td>\n",
              "      <td>0.846160</td>\n",
              "      <td>0.896539</td>\n",
              "      <td>0.981426</td>\n",
              "      <td>[0.980532867467493, 0.711786711494978]</td>\n",
              "      <td>[0.9924112523607169, 0.8006667871512684]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.026200</td>\n",
              "      <td>0.048293</td>\n",
              "      <td>0.847531</td>\n",
              "      <td>0.901853</td>\n",
              "      <td>0.981416</td>\n",
              "      <td>[0.9805093886613631, 0.7145526136044036]</td>\n",
              "      <td>[0.9917125899702696, 0.8119926567805881]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.025700</td>\n",
              "      <td>0.048967</td>\n",
              "      <td>0.846498</td>\n",
              "      <td>0.898646</td>\n",
              "      <td>0.981387</td>\n",
              "      <td>[0.9804863203025989, 0.7125098478880068]</td>\n",
              "      <td>[0.9920941199865655, 0.8051982764360655]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.049243</td>\n",
              "      <td>0.846454</td>\n",
              "      <td>0.898309</td>\n",
              "      <td>0.981395</td>\n",
              "      <td>[0.9804955699249517, 0.7124130593912704]</td>\n",
              "      <td>[0.99214678269033, 0.804471564048663]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
            "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7120, training_loss=0.030945719163236993, metrics={'train_runtime': 1370.9482, 'train_samples_per_second': 20.745, 'train_steps_per_second': 5.193, 'total_flos': 4.9849505503248384e+17, 'train_loss': 0.030945719163236993, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}