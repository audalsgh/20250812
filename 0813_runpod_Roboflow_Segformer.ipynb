{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7079e5f9-357a-49c8-9af6-2a2f1a438098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/lane_seg\n",
      "Collecting transformers==4.55.0 (from -r requirements.txt (line 1))\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting accelerate>=0.33.0 (from -r requirements.txt (line 2))\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate>=0.4.2 (from -r requirements.txt (line 3))\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.8.0.dev20250319+cu128)\n",
      "Collecting opencv-python-headless>=4.8 (from -r requirements.txt (line 5))\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow>=10.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.0->-r requirements.txt (line 1)) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting xxhash (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3)) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->-r requirements.txt (line 4)) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.1->-r requirements.txt (line 4)) (77.0.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.0->-r requirements.txt (line 1))\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.1->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate>=0.4.2->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate>=0.4.2->-r requirements.txt (line 3))\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate>=0.4.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, safetensors, regex, pyarrow, propcache, opencv-python-headless, multidict, hf-xet, frozenlist, dill, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, accelerate, datasets, evaluate\n",
      "Successfully installed accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 evaluate-0.4.5 frozenlist-1.7.0 hf-xet-1.1.7 huggingface-hub-0.34.4 multidict-6.6.4 multiprocess-0.70.16 opencv-python-headless-4.12.0.88 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 regex-2025.7.34 safetensors-0.6.2 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.0 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/lane_seg\n",
    "\n",
    "req = \"\"\"\\\n",
    "transformers==4.55.0\n",
    "accelerate>=0.33.0\n",
    "evaluate>=0.4.2\n",
    "torch>=2.1\n",
    "opencv-python-headless>=4.8\n",
    "pillow>=10.3\n",
    "numpy>=1.26\n",
    "\"\"\"\n",
    "with open(\"requirements.txt\",\"w\") as f:\n",
    "    f.write(req)\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f54348-5317-4b48-a078-598305a22c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP_PATH = /workspace/---.v1i.png-mask-semantic.zip\n",
      "✅ Unzipped to: /workspace/ds_rf\n",
      "📂 Top-level: ['valid', 'train', 'test', 'README.roboflow.txt', 'README.dataset.txt']\n"
     ]
    }
   ],
   "source": [
    "import os, glob, zipfile, shutil\n",
    "\n",
    "# 1) ZIP 자동 탐색 (이름에 'png-mask-semantic' 들어간 걸 찾아요)\n",
    "cands = sorted(glob.glob(\"/workspace/*png-mask-semantic*.zip\"))\n",
    "if not cands:\n",
    "    raise FileNotFoundError(\"'/workspace'에 *png-mask-semantic*.zip이 없습니다. Files 패널로 업로드했는지 확인!\")\n",
    "ZIP_PATH = cands[0]  # 첫 번째 걸 사용\n",
    "print(\"ZIP_PATH =\", ZIP_PATH)\n",
    "\n",
    "# 2) 압축 풀 대상 폴더\n",
    "EXTRACT_DIR = \"/workspace/ds_rf\"   # <- 여기가 extract_dir (원하면 다른 폴더명도 가능)\n",
    "\n",
    "# 3) 깨끗이 비우고 다시 생성\n",
    "if os.path.isdir(EXTRACT_DIR):\n",
    "    shutil.rmtree(EXTRACT_DIR)\n",
    "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "\n",
    "# 4) 압축 해제\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "    z.extractall(EXTRACT_DIR)\n",
    "\n",
    "print(\"✅ Unzipped to:\", EXTRACT_DIR)\n",
    "print(\"📂 Top-level:\", os.listdir(EXTRACT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1090dce-04ce-4ddc-b8dd-c95ae4be76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ scripts written to /workspace/lane_seg\n"
     ]
    }
   ],
   "source": [
    "# === train_segformer.py 저장 (Transformers 4.x용) ===\n",
    "train_py = r'''\n",
    "import os, glob, re, argparse, numpy as np, evaluate, torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    SegformerImageProcessor, SegformerForSemanticSegmentation,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "def is_img(n): return n.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"))\n",
    "def find_splits(root):\n",
    "    out={}\n",
    "    for n in (\"train\",\"valid\",\"val\",\"test\"):\n",
    "        p=os.path.join(root,n)\n",
    "        if os.path.isdir(p): out[\"valid\" if n in (\"valid\",\"val\") else n]=p\n",
    "    return out\n",
    "\n",
    "_SUFFIX_RE = re.compile(r'(_|-)(mask|masks|label|labels|seg|segment|segmentation)$', re.I)\n",
    "def stem_no_suffix(p):\n",
    "    s=os.path.splitext(os.path.basename(p))[0]\n",
    "    return _SUFFIX_RE.sub('', s)\n",
    "\n",
    "class RFSegFolder(Dataset):\n",
    "    def __init__(self, split_dir, processor, collapse_to_binary=True):\n",
    "        img_cands=[os.path.join(split_dir,\"images\"), split_dir]\n",
    "        self.img_dir=None\n",
    "        for d in img_cands:\n",
    "            if os.path.isdir(d) and any(is_img(f) for f in os.listdir(d)):\n",
    "                self.img_dir=d; break\n",
    "        if self.img_dir is None: raise RuntimeError(f\"No images in {split_dir}\")\n",
    "\n",
    "        mask_cands=[\"masks\",\"labels\",\"annotations\",\"masks_png\",\"labels_png\",\"mask\",\"Labels\",\"Masks\"]\n",
    "        self.mask_dirs=[os.path.join(split_dir,c) for c in mask_cands if os.path.isdir(os.path.join(split_dir,c))]\n",
    "        if not self.mask_dirs:\n",
    "            self.mask_dirs=[]\n",
    "            for r,_,files in os.walk(split_dir):\n",
    "                if os.path.abspath(r)==os.path.abspath(self.img_dir): continue\n",
    "                if any(f.lower().endswith(\".png\") for f in files): self.mask_dirs.append(r)\n",
    "            if not self.mask_dirs: self.mask_dirs=[split_dir]\n",
    "\n",
    "        mask_map={}\n",
    "        for md in self.mask_dirs:\n",
    "            for p in glob.glob(os.path.join(md,\"*.png\")):\n",
    "                mask_map[stem_no_suffix(p)]=p\n",
    "\n",
    "        self.items=[]\n",
    "        for ip in sorted(glob.glob(os.path.join(self.img_dir,\"*.*\"))):\n",
    "            if not is_img(ip): continue\n",
    "            mp = mask_map.get(stem_no_suffix(ip))\n",
    "            if mp and os.path.exists(mp): self.items.append((ip,mp))\n",
    "        if not self.items: raise RuntimeError(f\"No (image,mask) pairs in {split_dir}\")\n",
    "\n",
    "        self.processor=processor\n",
    "        self.collapse_to_binary=collapse_to_binary\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, idx):\n",
    "        ip, mp = self.items[idx]\n",
    "        image = Image.open(ip).convert(\"RGB\")\n",
    "        m = np.array(Image.open(mp).convert(\"L\"), dtype=np.uint8)\n",
    "        if self.collapse_to_binary: m = (m>0).astype(np.uint8)  # 0/1\n",
    "        enc = self.processor(images=image, segmentation_maps=m, return_tensors=\"pt\")\n",
    "        return {k:v.squeeze(0) for k,v in enc.items()}\n",
    "\n",
    "def to_py(o):\n",
    "    import numpy as np\n",
    "    if isinstance(o,np.ndarray): return o.tolist()\n",
    "    if isinstance(o,(np.floating,np.integer)): return o.item()\n",
    "    return o\n",
    "\n",
    "def main():\n",
    "    ap=argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_dir\", default=\"/workspace/ds_rf\")\n",
    "    ap.add_argument(\"--output_dir\", default=\"/workspace/segformer-lane\")\n",
    "    ap.add_argument(\"--epochs\", type=int, default=20)\n",
    "    ap.add_argument(\"--batch\", type=int, default=4)\n",
    "    ap.add_argument(\"--ckpt\", default=\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "    ap.add_argument(\"--binary\", action=\"store_true\")\n",
    "    args=ap.parse_args()\n",
    "\n",
    "    splits=find_splits(args.data_dir)\n",
    "    if not splits: raise RuntimeError(f\"No train/valid/test under {args.data_dir}\")\n",
    "\n",
    "    class_names=[\"background\",\"lane\"] if args.binary else [\"background\",\"lane\",\"lane-dot\",\"lane-mid\",\"lane_crosswalk\"]\n",
    "    id2label={i:n for i,n in enumerate(class_names)}\n",
    "    label2id={n:i for i,n in id2label.items()}\n",
    "    num_labels=len(class_names)\n",
    "\n",
    "    processor=SegformerImageProcessor.from_pretrained(args.ckpt)\n",
    "    model=SegformerForSemanticSegmentation.from_pretrained(\n",
    "        args.ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    train_dir=splits.get(\"train\")\n",
    "    valid_dir=splits.get(\"valid\") or splits.get(\"val\") or train_dir\n",
    "    train_ds=RFSegFolder(train_dir, processor, collapse_to_binary=args.binary)\n",
    "    val_ds  =RFSegFolder(valid_dir,   processor, collapse_to_binary=args.binary)\n",
    "\n",
    "    metric=evaluate.load(\"mean_iou\")\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        if isinstance(logits,tuple): logits=logits[0]\n",
    "        lt=torch.from_numpy(logits); yt=torch.from_numpy(labels)\n",
    "        up=torch.nn.functional.interpolate(lt, size=yt.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        preds=up.argmax(dim=1).cpu().numpy()\n",
    "        res=metric.compute(predictions=preds, references=labels, num_labels=num_labels, ignore_index=255, reduce_labels=False)\n",
    "        return {k:to_py(v) for k,v in res.items()}\n",
    "\n",
    "    args_tr=TrainingArguments(\n",
    "        output_dir=args.output_dir, learning_rate=5e-5,\n",
    "        num_train_epochs=args.epochs,\n",
    "        per_device_train_batch_size=args.batch,\n",
    "        per_device_eval_batch_size=args.batch,\n",
    "        evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "        fp16=torch.cuda.is_available(), logging_steps=50,\n",
    "        load_best_model_at_end=True, metric_for_best_model=\"mean_iou\",\n",
    "        greater_is_better=True, report_to=\"none\", seed=42,\n",
    "    )\n",
    "\n",
    "    trainer=Trainer(model=model, args=args_tr, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "\n",
    "    best=os.path.join(args.output_dir,\"best\"); os.makedirs(best,exist_ok=True)\n",
    "    trainer.save_model(best); processor.save_pretrained(best)\n",
    "    print(f\"✅ Saved to {best}\")\n",
    "\n",
    "if __name__==\"__main__\": main()\n",
    "'''\n",
    "open(\"/workspace/lane_seg/train_segformer.py\",\"w\").write(train_py)\n",
    "\n",
    "# === infer_segformer_video.py 저장 ===\n",
    "infer_py = r'''\n",
    "import os, glob, argparse, cv2, numpy as np, torch\n",
    "from PIL import Image\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "\n",
    "def load_model(model_dir, device):\n",
    "    processor=SegformerImageProcessor.from_pretrained(model_dir)\n",
    "    model=SegformerForSemanticSegmentation.from_pretrained(model_dir).to(device).eval()\n",
    "    return processor, model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_mask(proc, model, bgr):\n",
    "    img=Image.fromarray(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
    "    inputs=proc(images=img, return_tensors=\"pt\").to(model.device)\n",
    "    logits=model(**inputs).logits\n",
    "    up=torch.nn.functional.interpolate(logits, size=img.size[::-1], mode=\"bilinear\", align_corners=False)\n",
    "    return up.argmax(dim=1)[0].cpu().numpy().astype(np.uint8)\n",
    "\n",
    "def overlay(bgr, mask, alpha=0.5):\n",
    "    color=np.zeros_like(bgr); color[mask==1]=(255,0,0)\n",
    "    return cv2.addWeighted(bgr,1.0,color,alpha,0)\n",
    "\n",
    "def write_video(frames, out_path, fps=15):\n",
    "    h,w=frames[0].shape[:2]\n",
    "    for fourcc_str in [\"mp4v\",\"avc1\",\"XVID\"]:\n",
    "        vw=cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*fourcc_str), fps, (w,h))\n",
    "        if vw.isOpened():\n",
    "            for f in frames: vw.write(f)\n",
    "            vw.release()\n",
    "            if os.path.exists(out_path) and os.path.getsize(out_path)>0: return\n",
    "    raise RuntimeError(\"Video write failed; try different codec/ext.\")\n",
    "\n",
    "def run_on_video(model_dir, input_path, output_path, alpha=0.5, fps=None, device=\"cuda\"):\n",
    "    device = device if (device==\"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "    proc, model = load_model(model_dir, device)\n",
    "    cap=cv2.VideoCapture(input_path); assert cap.isOpened(), f\"cannot open {input_path}\"\n",
    "    frames=[]; src_fps=cap.get(cv2.CAP_PROP_FPS) or 15; use_fps=fps or src_fps\n",
    "    while True:\n",
    "        ok,frame=cap.read()\n",
    "        if not ok: break\n",
    "        m=predict_mask(proc, model, frame)\n",
    "        frames.append(overlay(frame,m,alpha))\n",
    "    cap.release(); write_video(frames,output_path,use_fps); print(\"✅ Saved:\",output_path)\n",
    "\n",
    "def run_on_images(model_dir, images_dir, output_path, alpha=0.5, fps=15, device=\"cuda\"):\n",
    "    device = device if (device==\"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "    proc, model = load_model(model_dir, device)\n",
    "    paths=sorted([p for p in glob.glob(os.path.join(images_dir,\"*\")) if os.path.isfile(p)])\n",
    "    assert paths, f\"No images in {images_dir}\"\n",
    "    frames=[]\n",
    "    for p in paths:\n",
    "        bgr=cv2.imread(p); \n",
    "        if bgr is None: continue\n",
    "        m=predict_mask(proc, model, bgr)\n",
    "        frames.append(overlay(bgr,m,alpha))\n",
    "    write_video(frames,output_path,fps); print(\"✅ Saved:\",output_path)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    ap=argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--model_dir\",required=True)\n",
    "    ap.add_argument(\"--input\"); ap.add_argument(\"--images_dir\")\n",
    "    ap.add_argument(\"--output\",required=True)\n",
    "    ap.add_argument(\"--alpha\",type=float,default=0.5)\n",
    "    ap.add_argument(\"--fps\",type=int,default=None)\n",
    "    ap.add_argument(\"--device\",default=\"cuda\")\n",
    "    args=ap.parse_args()\n",
    "    if (args.input is None)==(args.images_dir is None):\n",
    "        raise SystemExit(\"Use exactly one of --input or --images_dir\")\n",
    "    if args.input:  run_on_video(args.model_dir,args.input,args.output,args.alpha,args.fps,args.device)\n",
    "    else:           run_on_images(args.model_dir,args.images_dir,args.output,args.alpha,args.fps or 15,args.device)\n",
    "'''\n",
    "open(\"/workspace/lane_seg/infer_segformer_video.py\",\"w\").write(infer_py)\n",
    "print(\"✅ scripts written to /workspace/lane_seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5aec3d9-751c-4f57-9d6f-3ae366734edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/image_processing_base.py:412: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "{'loss': 0.4281, 'grad_norm': 3.0016708374023438, 'learning_rate': 4.9655898876404494e-05, 'epoch': 0.14}\n",
      "{'loss': 0.294, 'grad_norm': 1.652809739112854, 'learning_rate': 4.930477528089888e-05, 'epoch': 0.28}\n",
      "{'loss': 0.196, 'grad_norm': 1.5567960739135742, 'learning_rate': 4.895365168539326e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1499, 'grad_norm': 0.8386121392250061, 'learning_rate': 4.860252808988764e-05, 'epoch': 0.56}\n",
      "{'loss': 0.1177, 'grad_norm': 0.5320227146148682, 'learning_rate': 4.825140449438202e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1012, 'grad_norm': 0.6887598037719727, 'learning_rate': 4.79002808988764e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0868, 'grad_norm': 0.8528304696083069, 'learning_rate': 4.754915730337079e-05, 'epoch': 0.98}\n",
      "  5%|██                                      | 356/7120 [00:52<14:41,  7.67it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:01, 11.34it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 10.17it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.06it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.57it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:00,  9.66it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  9.50it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.36it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.27it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.18it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.14it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.08it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  8.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 17/18 [00:01<00:00,  9.23it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.0874379500746727, 'eval_mean_iou': 0.7921045257996071, 'eval_mean_accuracy': 0.8472018023205599, 'eval_overall_accuracy': 0.9743304116385324, 'eval_per_category_iou': [0.9732521591272771, 0.6109568924719371], 'eval_per_category_accuracy': [0.9907824082290244, 0.7036211964120954], 'eval_runtime': 3.3641, 'eval_samples_per_second': 20.808, 'eval_steps_per_second': 5.351, 'epoch': 1.0}\n",
      "  5%|██                                      | 356/7120 [00:55<14:41,  7.67it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.23it/s]\u001b[A\n",
      "{'loss': 0.0836, 'grad_norm': 0.42631658911705017, 'learning_rate': 4.719803370786517e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0752, 'grad_norm': 0.40166279673576355, 'learning_rate': 4.684691011235955e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0699, 'grad_norm': 0.31615957617759705, 'learning_rate': 4.649578651685393e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0658, 'grad_norm': 0.8783314228057861, 'learning_rate': 4.614466292134832e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0644, 'grad_norm': 0.27629002928733826, 'learning_rate': 4.57935393258427e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0586, 'grad_norm': 0.28485554456710815, 'learning_rate': 4.544241573033708e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0571, 'grad_norm': 0.43156135082244873, 'learning_rate': 4.509129213483146e-05, 'epoch': 1.97}\n",
      " 10%|████                                    | 712/7120 [01:46<10:51,  9.83it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 18.53it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.64it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.49it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.65it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.43it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.42it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.42it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.40it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.39it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.42it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.41it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.061927154660224915, 'eval_mean_iou': 0.8145285053030109, 'eval_mean_accuracy': 0.8684795162169124, 'eval_overall_accuracy': 0.9772796630859375, 'eval_per_category_iou': [0.9762658155788062, 0.6527911950272157], 'eval_per_category_accuracy': [0.991359732512774, 0.7455992999210509], 'eval_runtime': 4.794, 'eval_samples_per_second': 14.602, 'eval_steps_per_second': 3.755, 'epoch': 2.0}\n",
      " 10%|████                                    | 712/7120 [01:51<10:51,  9.83it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:04<00:00,  9.41it/s]\u001b[A\n",
      "{'loss': 0.0574, 'grad_norm': 0.30695661902427673, 'learning_rate': 4.474016853932584e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0519, 'grad_norm': 0.4857630133628845, 'learning_rate': 4.438904494382023e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0555, 'grad_norm': 0.3959190547466278, 'learning_rate': 4.403792134831461e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0495, 'grad_norm': 0.24611186981201172, 'learning_rate': 4.368679775280899e-05, 'epoch': 2.53}\n",
      "{'loss': 0.0472, 'grad_norm': 0.26374635100364685, 'learning_rate': 4.333567415730337e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0511, 'grad_norm': 0.17544011771678925, 'learning_rate': 4.298455056179775e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0543, 'grad_norm': 0.32529371976852417, 'learning_rate': 4.263342696629214e-05, 'epoch': 2.95}\n",
      " 15%|█████▊                                 | 1068/7120 [02:43<10:15,  9.83it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:01, 11.63it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01,  9.91it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01,  9.41it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:00<00:01,  9.32it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:01<00:01,  5.98it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:01<00:01,  6.64it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:01,  7.23it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  8.00it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  8.19it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  8.18it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  8.37it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  8.54it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.05495917424559593, 'eval_mean_iou': 0.8248534903604086, 'eval_mean_accuracy': 0.8830611254675729, 'eval_overall_accuracy': 0.978351320539202, 'eval_per_category_iou': [0.9773448343136951, 0.6723621464071219], 'eval_per_category_accuracy': [0.9906830370020527, 0.775439213933093], 'eval_runtime': 3.7679, 'eval_samples_per_second': 18.578, 'eval_steps_per_second': 4.777, 'epoch': 3.0}\n",
      " 15%|█████▊                                 | 1068/7120 [02:47<10:15,  9.83it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  8.54it/s]\u001b[A\n",
      "{'loss': 0.0477, 'grad_norm': 0.7094213962554932, 'learning_rate': 4.228230337078652e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0468, 'grad_norm': 0.23417183756828308, 'learning_rate': 4.19311797752809e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0448, 'grad_norm': 0.41422751545906067, 'learning_rate': 4.158005617977529e-05, 'epoch': 3.37}\n",
      "{'loss': 0.05, 'grad_norm': 0.21867071092128754, 'learning_rate': 4.122893258426966e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0465, 'grad_norm': 0.1131405308842659, 'learning_rate': 4.087780898876405e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0418, 'grad_norm': 0.18773137032985687, 'learning_rate': 4.052668539325843e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0444, 'grad_norm': 0.3513905704021454, 'learning_rate': 4.017556179775281e-05, 'epoch': 3.93}\n",
      " 20%|███████▊                               | 1424/7120 [03:36<09:29,  9.99it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▎                                    | 3/18 [00:00<00:01, 13.90it/s]\u001b[A\n",
      " 28%|████████████▏                               | 5/18 [00:00<00:01, 11.99it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:00<00:00, 11.27it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:00, 11.18it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:00<00:00, 11.06it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00, 10.61it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00, 10.64it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 17/18 [00:01<00:00,  9.91it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.050445735454559326, 'eval_mean_iou': 0.835750565492701, 'eval_mean_accuracy': 0.8928651138575696, 'eval_overall_accuracy': 0.9797989981515067, 'eval_per_category_iou': [0.9788354006343499, 0.6926657303510521], 'eval_per_category_accuracy': [0.9910493058176969, 0.7946809218974422], 'eval_runtime': 3.2214, 'eval_samples_per_second': 21.73, 'eval_steps_per_second': 5.588, 'epoch': 4.0}\n",
      " 20%|███████▊                               | 1424/7120 [03:39<09:29,  9.99it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.91it/s]\u001b[A\n",
      "{'loss': 0.042, 'grad_norm': 0.30986547470092773, 'learning_rate': 3.98244382022472e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0403, 'grad_norm': 0.4016279876232147, 'learning_rate': 3.947331460674157e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0459, 'grad_norm': 0.22834934294223785, 'learning_rate': 3.912219101123596e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0437, 'grad_norm': 0.5401163101196289, 'learning_rate': 3.877106741573034e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0387, 'grad_norm': 0.3322155475616455, 'learning_rate': 3.841994382022472e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0425, 'grad_norm': 0.29069820046424866, 'learning_rate': 3.8068820224719107e-05, 'epoch': 4.78}\n",
      "{'loss': 0.0463, 'grad_norm': 1.143367052078247, 'learning_rate': 3.771769662921348e-05, 'epoch': 4.92}\n",
      " 25%|█████████▊                             | 1780/7120 [04:31<09:38,  9.23it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▎                                    | 3/18 [00:00<00:01, 12.41it/s]\u001b[A\n",
      " 28%|████████████▏                               | 5/18 [00:00<00:01, 10.66it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:00<00:01, 10.58it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:00, 10.58it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00, 10.19it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00, 10.11it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00, 10.26it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 17/18 [00:01<00:00, 10.08it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.05033029243350029, 'eval_mean_iou': 0.8284777141765596, 'eval_mean_accuracy': 0.8787156840043426, 'eval_overall_accuracy': 0.9792431967599051, 'eval_per_category_iou': [0.978291529975538, 0.6786638983775812], 'eval_per_category_accuracy': [0.9922526861736413, 0.7651786818350439], 'eval_runtime': 3.1986, 'eval_samples_per_second': 21.885, 'eval_steps_per_second': 5.627, 'epoch': 5.0}\n",
      " 25%|█████████▊                             | 1780/7120 [04:34<09:38,  9.23it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00, 10.08it/s]\u001b[A\n",
      "{'loss': 0.0358, 'grad_norm': 0.2624831199645996, 'learning_rate': 3.736657303370787e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0369, 'grad_norm': 0.3098832964897156, 'learning_rate': 3.701544943820225e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0435, 'grad_norm': 0.3177175223827362, 'learning_rate': 3.666432584269663e-05, 'epoch': 5.34}\n",
      "{'loss': 0.0387, 'grad_norm': 0.27767887711524963, 'learning_rate': 3.6313202247191016e-05, 'epoch': 5.48}\n",
      "{'loss': 0.043, 'grad_norm': 0.7630279064178467, 'learning_rate': 3.59620786516854e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0407, 'grad_norm': 0.22953678667545319, 'learning_rate': 3.561095505617978e-05, 'epoch': 5.76}\n",
      "{'loss': 0.0387, 'grad_norm': 0.261666864156723, 'learning_rate': 3.525983146067416e-05, 'epoch': 5.9}\n",
      " 30%|███████████▋                           | 2136/7120 [05:25<09:30,  8.74it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 17.99it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.75it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.36it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  8.87it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:01,  8.96it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  8.94it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.06it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  8.97it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  8.16it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  8.40it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  8.69it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  8.82it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.049311429262161255, 'eval_mean_iou': 0.8428833051895713, 'eval_mean_accuracy': 0.9123819182678076, 'eval_overall_accuracy': 0.9801196507045201, 'eval_per_category_iou': [0.9791197147003204, 0.7066468956788222], 'eval_per_category_accuracy': [0.9888857415874076, 0.8358780949482075], 'eval_runtime': 3.2811, 'eval_samples_per_second': 21.334, 'eval_steps_per_second': 5.486, 'epoch': 6.0}\n",
      " 30%|███████████▋                           | 2136/7120 [05:29<09:30,  8.74it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  8.82it/s]\u001b[A\n",
      "{'loss': 0.041, 'grad_norm': 0.26621973514556885, 'learning_rate': 3.490870786516854e-05, 'epoch': 6.04}\n",
      "{'loss': 0.0366, 'grad_norm': 0.4380209445953369, 'learning_rate': 3.4557584269662926e-05, 'epoch': 6.18}\n",
      "{'loss': 0.035, 'grad_norm': 0.3755311667919159, 'learning_rate': 3.4206460674157306e-05, 'epoch': 6.32}\n",
      "{'loss': 0.0342, 'grad_norm': 0.3020283281803131, 'learning_rate': 3.385533707865169e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0411, 'grad_norm': 0.2706606090068817, 'learning_rate': 3.350421348314607e-05, 'epoch': 6.6}\n",
      "{'loss': 0.0369, 'grad_norm': 0.9998371005058289, 'learning_rate': 3.315308988764045e-05, 'epoch': 6.74}\n",
      "{'loss': 0.038, 'grad_norm': 0.5219926834106445, 'learning_rate': 3.2801966292134835e-05, 'epoch': 6.88}\n",
      " 35%|█████████████▋                         | 2492/7120 [06:20<08:20,  9.25it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▎                                    | 3/18 [00:00<00:00, 15.87it/s]\u001b[A\n",
      " 28%|████████████▏                               | 5/18 [00:00<00:01, 12.58it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:00<00:00, 11.40it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:00, 11.03it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:00<00:00, 10.82it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00, 10.52it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00, 10.31it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 17/18 [00:01<00:00, 10.83it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.047146961092948914, 'eval_mean_iou': 0.8396419933230037, 'eval_mean_accuracy': 0.8853657287947625, 'eval_overall_accuracy': 0.9808478219168527, 'eval_per_category_iou': [0.9799548933196552, 0.6993290933263522], 'eval_per_category_accuracy': [0.9932043723339867, 0.7775270852555384], 'eval_runtime': 2.9126, 'eval_samples_per_second': 24.034, 'eval_steps_per_second': 6.18, 'epoch': 7.0}\n",
      " 35%|█████████████▋                         | 2492/7120 [06:23<08:20,  9.25it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00, 10.83it/s]\u001b[A\n",
      "{'loss': 0.0418, 'grad_norm': 0.44740602374076843, 'learning_rate': 3.2450842696629216e-05, 'epoch': 7.02}\n",
      "{'loss': 0.0366, 'grad_norm': 0.47595342993736267, 'learning_rate': 3.2099719101123597e-05, 'epoch': 7.16}\n",
      "{'loss': 0.034, 'grad_norm': 0.2444152534008026, 'learning_rate': 3.174859550561798e-05, 'epoch': 7.3}\n",
      "{'loss': 0.036, 'grad_norm': 0.25110939145088196, 'learning_rate': 3.1397471910112364e-05, 'epoch': 7.44}\n",
      "{'loss': 0.0361, 'grad_norm': 0.621194064617157, 'learning_rate': 3.1046348314606745e-05, 'epoch': 7.58}\n",
      "{'loss': 0.0358, 'grad_norm': 0.26588350534439087, 'learning_rate': 3.0695224719101126e-05, 'epoch': 7.72}\n",
      "{'loss': 0.0364, 'grad_norm': 0.14846102893352509, 'learning_rate': 3.034410112359551e-05, 'epoch': 7.87}\n",
      " 40%|███████████████▌                       | 2847/7120 [07:13<09:15,  7.69it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▎                                    | 3/18 [00:00<00:01, 14.64it/s]\u001b[A\n",
      " 28%|████████████▏                               | 5/18 [00:00<00:01, 11.96it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:00<00:00, 11.03it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:00,  9.97it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.78it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.92it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.98it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 17/18 [00:01<00:00, 10.42it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04710371419787407, 'eval_mean_iou': 0.8432323772396909, 'eval_mean_accuracy': 0.9081670650830262, 'eval_overall_accuracy': 0.9803793225969587, 'eval_per_category_iou': [0.9794039342129026, 0.7070608202664792], 'eval_per_category_accuracy': [0.9897244717398983, 0.8266096584261541], 'eval_runtime': 3.0855, 'eval_samples_per_second': 22.687, 'eval_steps_per_second': 5.834, 'epoch': 8.0}\n",
      " 40%|███████████████▌                       | 2848/7120 [07:16<09:15,  7.69it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00, 10.42it/s]\u001b[A\n",
      "{'loss': 0.0328, 'grad_norm': 0.3491954803466797, 'learning_rate': 2.9992977528089887e-05, 'epoch': 8.01}\n",
      "{'loss': 0.0322, 'grad_norm': 0.11407869309186935, 'learning_rate': 2.9641853932584274e-05, 'epoch': 8.15}\n",
      "{'loss': 0.0332, 'grad_norm': 0.19466844201087952, 'learning_rate': 2.9290730337078655e-05, 'epoch': 8.29}\n",
      "{'loss': 0.0336, 'grad_norm': 0.12352646887302399, 'learning_rate': 2.8939606741573032e-05, 'epoch': 8.43}\n",
      "{'loss': 0.0341, 'grad_norm': 0.2524740397930145, 'learning_rate': 2.858848314606742e-05, 'epoch': 8.57}\n",
      "{'loss': 0.0322, 'grad_norm': 0.2010234147310257, 'learning_rate': 2.82373595505618e-05, 'epoch': 8.71}\n",
      "{'loss': 0.0398, 'grad_norm': 0.14453551173210144, 'learning_rate': 2.7886235955056184e-05, 'epoch': 8.85}\n",
      "{'loss': 0.0341, 'grad_norm': 0.6566373109817505, 'learning_rate': 2.7535112359550564e-05, 'epoch': 8.99}\n",
      " 45%|█████████████████▌                     | 3204/7120 [08:09<06:55,  9.41it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 16.65it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.13it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.08it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.57it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.69it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.58it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.53it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.57it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.61it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.43it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.22it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.045046523213386536, 'eval_mean_iou': 0.8472456644077395, 'eval_mean_accuracy': 0.9053596779501094, 'eval_overall_accuracy': 0.9812082018171038, 'eval_per_category_iou': [0.9802822179778671, 0.714209110837612], 'eval_per_category_accuracy': [0.9910239282908554, 0.8196954276093635], 'eval_runtime': 3.2011, 'eval_samples_per_second': 21.867, 'eval_steps_per_second': 5.623, 'epoch': 9.0}\n",
      " 45%|█████████████████▌                     | 3204/7120 [08:12<06:55,  9.41it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00,  9.22it/s]\u001b[A\n",
      "{'loss': 0.0339, 'grad_norm': 0.6804466247558594, 'learning_rate': 2.718398876404494e-05, 'epoch': 9.13}\n",
      "{'loss': 0.0343, 'grad_norm': 0.5838431119918823, 'learning_rate': 2.683286516853933e-05, 'epoch': 9.27}\n",
      "{'loss': 0.0314, 'grad_norm': 0.3594089150428772, 'learning_rate': 2.648174157303371e-05, 'epoch': 9.41}\n",
      "{'loss': 0.0315, 'grad_norm': 1.479419469833374, 'learning_rate': 2.6130617977528093e-05, 'epoch': 9.55}\n",
      "{'loss': 0.0295, 'grad_norm': 0.09798613935709, 'learning_rate': 2.5779494382022474e-05, 'epoch': 9.69}\n",
      "{'loss': 0.0333, 'grad_norm': 0.29458123445510864, 'learning_rate': 2.5428370786516854e-05, 'epoch': 9.83}\n",
      "{'loss': 0.0357, 'grad_norm': 0.6408973932266235, 'learning_rate': 2.507724719101124e-05, 'epoch': 9.97}\n",
      " 50%|███████████████████▌                   | 3560/7120 [09:04<06:35,  8.99it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 19.36it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 12.06it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.62it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.99it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.70it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.25it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.31it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  8.77it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  8.80it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  8.93it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04472406953573227, 'eval_mean_iou': 0.8472761348672313, 'eval_mean_accuracy': 0.898480764290285, 'eval_overall_accuracy': 0.9815260205950056, 'eval_per_category_iou': [0.9806331692632293, 0.7139191004712332], 'eval_per_category_accuracy': [0.9922730922487553, 0.8046884363318146], 'eval_runtime': 3.2244, 'eval_samples_per_second': 21.71, 'eval_steps_per_second': 5.582, 'epoch': 10.0}\n",
      " 50%|███████████████████▌                   | 3560/7120 [09:07<06:35,  8.99it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  8.93it/s]\u001b[A\n",
      "{'loss': 0.0337, 'grad_norm': 0.18279415369033813, 'learning_rate': 2.472612359550562e-05, 'epoch': 10.11}\n",
      "{'loss': 0.0342, 'grad_norm': 0.2941757142543793, 'learning_rate': 2.4375e-05, 'epoch': 10.25}\n",
      "{'loss': 0.032, 'grad_norm': 0.15313008427619934, 'learning_rate': 2.4023876404494384e-05, 'epoch': 10.39}\n",
      "{'loss': 0.0306, 'grad_norm': 0.10852701961994171, 'learning_rate': 2.3672752808988764e-05, 'epoch': 10.53}\n",
      "{'loss': 0.0309, 'grad_norm': 0.2243470549583435, 'learning_rate': 2.3321629213483148e-05, 'epoch': 10.67}\n",
      "{'loss': 0.0364, 'grad_norm': 0.2592705488204956, 'learning_rate': 2.297050561797753e-05, 'epoch': 10.81}\n",
      "{'loss': 0.0276, 'grad_norm': 0.6614840626716614, 'learning_rate': 2.261938202247191e-05, 'epoch': 10.96}\n",
      " 55%|█████████████████████▍                 | 3916/7120 [09:58<05:23,  9.90it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 19.18it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.67it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.46it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:00, 10.01it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.72it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.55it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.50it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.54it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.51it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.48it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04569112882018089, 'eval_mean_iou': 0.8429635313264959, 'eval_mean_accuracy': 0.8948943439758313, 'eval_overall_accuracy': 0.9809576851981027, 'eval_per_category_iou': [0.9800457494770424, 0.7058813131759495], 'eval_per_category_accuracy': [0.9920953339457083, 0.7976933540059544], 'eval_runtime': 3.1942, 'eval_samples_per_second': 21.915, 'eval_steps_per_second': 5.635, 'epoch': 11.0}\n",
      " 55%|█████████████████████▍                 | 3916/7120 [10:01<05:23,  9.90it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.48it/s]\u001b[A\n",
      "{'loss': 0.0282, 'grad_norm': 0.24504919350147247, 'learning_rate': 2.2268258426966293e-05, 'epoch': 11.1}\n",
      "{'loss': 0.0348, 'grad_norm': 0.43691664934158325, 'learning_rate': 2.1917134831460677e-05, 'epoch': 11.24}\n",
      "{'loss': 0.0322, 'grad_norm': 0.2891402542591095, 'learning_rate': 2.1566011235955058e-05, 'epoch': 11.38}\n",
      "{'loss': 0.0276, 'grad_norm': 0.3595373034477234, 'learning_rate': 2.1214887640449438e-05, 'epoch': 11.52}\n",
      "{'loss': 0.0342, 'grad_norm': 0.17308878898620605, 'learning_rate': 2.086376404494382e-05, 'epoch': 11.66}\n",
      "{'loss': 0.0259, 'grad_norm': 0.27173227071762085, 'learning_rate': 2.0512640449438203e-05, 'epoch': 11.8}\n",
      "{'loss': 0.0332, 'grad_norm': 0.16730555891990662, 'learning_rate': 2.0161516853932587e-05, 'epoch': 11.94}\n",
      " 60%|███████████████████████▍               | 4272/7120 [10:54<04:52,  9.73it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 18.86it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.84it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.33it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.52it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.36it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.36it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.39it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.41it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.44it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.40it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.37it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04619207978248596, 'eval_mean_iou': 0.8433734498826803, 'eval_mean_accuracy': 0.8942774422921165, 'eval_overall_accuracy': 0.9810570308140346, 'eval_per_category_iou': [0.9801515517997076, 0.7065953479656529], 'eval_per_category_accuracy': [0.9922873707205773, 0.7962675138636558], 'eval_runtime': 3.147, 'eval_samples_per_second': 22.244, 'eval_steps_per_second': 5.72, 'epoch': 12.0}\n",
      " 60%|███████████████████████▍               | 4272/7120 [10:57<04:52,  9.73it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00,  9.37it/s]\u001b[A\n",
      "{'loss': 0.0304, 'grad_norm': 0.17673765122890472, 'learning_rate': 1.9810393258426967e-05, 'epoch': 12.08}\n",
      "{'loss': 0.0282, 'grad_norm': 0.2095278799533844, 'learning_rate': 1.945926966292135e-05, 'epoch': 12.22}\n",
      "{'loss': 0.0319, 'grad_norm': 0.44831305742263794, 'learning_rate': 1.9108146067415732e-05, 'epoch': 12.36}\n",
      "{'loss': 0.0341, 'grad_norm': 0.324849009513855, 'learning_rate': 1.8757022471910112e-05, 'epoch': 12.5}\n",
      "{'loss': 0.0291, 'grad_norm': 0.39889076352119446, 'learning_rate': 1.8405898876404496e-05, 'epoch': 12.64}\n",
      "{'loss': 0.0272, 'grad_norm': 0.26511040329933167, 'learning_rate': 1.8054775280898877e-05, 'epoch': 12.78}\n",
      "{'loss': 0.0319, 'grad_norm': 0.6378504633903503, 'learning_rate': 1.770365168539326e-05, 'epoch': 12.92}\n",
      " 65%|█████████████████████████▎             | 4628/7120 [11:48<04:45,  8.73it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 17.96it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.05it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.25it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.83it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.61it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.17it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.28it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.27it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.28it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.21it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04562041163444519, 'eval_mean_iou': 0.8478897042811431, 'eval_mean_accuracy': 0.9005162196602431, 'eval_overall_accuracy': 0.9815375736781529, 'eval_per_category_iou': [0.9806402560978676, 0.7151391524644184], 'eval_per_category_accuracy': [0.9920227276274556, 0.8090097116930306], 'eval_runtime': 3.3068, 'eval_samples_per_second': 21.169, 'eval_steps_per_second': 5.443, 'epoch': 13.0}\n",
      " 65%|█████████████████████████▎             | 4628/7120 [11:51<04:45,  8.73it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.21it/s]\u001b[A\n",
      "{'loss': 0.0269, 'grad_norm': 0.18964964151382446, 'learning_rate': 1.735252808988764e-05, 'epoch': 13.06}\n",
      "{'loss': 0.0288, 'grad_norm': 0.2662954032421112, 'learning_rate': 1.7001404494382022e-05, 'epoch': 13.2}\n",
      "{'loss': 0.0337, 'grad_norm': 0.23889294266700745, 'learning_rate': 1.6650280898876406e-05, 'epoch': 13.34}\n",
      "{'loss': 0.0281, 'grad_norm': 0.12997201085090637, 'learning_rate': 1.6299157303370787e-05, 'epoch': 13.48}\n",
      "{'loss': 0.0255, 'grad_norm': 0.2971228361129761, 'learning_rate': 1.594803370786517e-05, 'epoch': 13.62}\n",
      "{'loss': 0.0311, 'grad_norm': 0.1344294250011444, 'learning_rate': 1.559691011235955e-05, 'epoch': 13.76}\n",
      "{'loss': 0.0305, 'grad_norm': 0.3240097463130951, 'learning_rate': 1.5245786516853933e-05, 'epoch': 13.9}\n",
      " 70%|███████████████████████████▎           | 4984/7120 [12:43<03:54,  9.11it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 18.24it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.83it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.50it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  8.76it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:00<00:01,  8.92it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  8.98it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.01it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.00it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.00it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.08it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.09it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.15it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04403504729270935, 'eval_mean_iou': 0.8492242758147204, 'eval_mean_accuracy': 0.9052680197585516, 'eval_overall_accuracy': 0.9815508161272322, 'eval_per_category_iou': [0.9806423923510964, 0.7178061592783445], 'eval_per_category_accuracy': [0.9914227427730411, 0.8191132967440622], 'eval_runtime': 3.8179, 'eval_samples_per_second': 18.335, 'eval_steps_per_second': 4.715, 'epoch': 14.0}\n",
      " 70%|███████████████████████████▎           | 4984/7120 [12:47<03:54,  9.11it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.15it/s]\u001b[A\n",
      "{'loss': 0.0304, 'grad_norm': 0.2929077744483948, 'learning_rate': 1.4894662921348316e-05, 'epoch': 14.04}\n",
      "{'loss': 0.029, 'grad_norm': 0.35479703545570374, 'learning_rate': 1.4543539325842698e-05, 'epoch': 14.19}\n",
      "{'loss': 0.0278, 'grad_norm': 0.18747369945049286, 'learning_rate': 1.419241573033708e-05, 'epoch': 14.33}\n",
      "{'loss': 0.0255, 'grad_norm': 0.0948844626545906, 'learning_rate': 1.384129213483146e-05, 'epoch': 14.47}\n",
      "{'loss': 0.0309, 'grad_norm': 0.1956624835729599, 'learning_rate': 1.3490168539325843e-05, 'epoch': 14.61}\n",
      "{'loss': 0.0276, 'grad_norm': 0.2607981264591217, 'learning_rate': 1.3139044943820225e-05, 'epoch': 14.75}\n",
      "{'loss': 0.0288, 'grad_norm': 0.3038272559642792, 'learning_rate': 1.2787921348314607e-05, 'epoch': 14.89}\n",
      " 75%|█████████████████████████████▏         | 5339/7120 [13:38<03:58,  7.48it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 18.99it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.70it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.36it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.90it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.51it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.40it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.33it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.29it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.21it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04451264813542366, 'eval_mean_iou': 0.8482127783298405, 'eval_mean_accuracy': 0.898234179387006, 'eval_overall_accuracy': 0.9816952841622489, 'eval_per_category_iou': [0.9808114388373146, 0.7156141178223665], 'eval_per_category_accuracy': [0.992496171693132, 0.80397218708088], 'eval_runtime': 3.1054, 'eval_samples_per_second': 22.541, 'eval_steps_per_second': 5.796, 'epoch': 15.0}\n",
      " 75%|█████████████████████████████▎         | 5340/7120 [13:41<03:58,  7.48it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00,  9.21it/s]\u001b[A\n",
      "{'loss': 0.0288, 'grad_norm': 0.15741616487503052, 'learning_rate': 1.2436797752808988e-05, 'epoch': 15.03}\n",
      "{'loss': 0.0257, 'grad_norm': 0.2188062220811844, 'learning_rate': 1.2085674157303372e-05, 'epoch': 15.17}\n",
      "{'loss': 0.0225, 'grad_norm': 0.2360997200012207, 'learning_rate': 1.1734550561797754e-05, 'epoch': 15.31}\n",
      "{'loss': 0.0316, 'grad_norm': 0.2678983509540558, 'learning_rate': 1.1383426966292135e-05, 'epoch': 15.45}\n",
      "{'loss': 0.033, 'grad_norm': 1.2715122699737549, 'learning_rate': 1.1032303370786517e-05, 'epoch': 15.59}\n",
      "{'loss': 0.0292, 'grad_norm': 0.35149988532066345, 'learning_rate': 1.06811797752809e-05, 'epoch': 15.73}\n",
      "{'loss': 0.0296, 'grad_norm': 0.2628172039985657, 'learning_rate': 1.0330056179775282e-05, 'epoch': 15.87}\n",
      " 80%|███████████████████████████████▏       | 5696/7120 [14:30<02:23,  9.94it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 19.11it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.88it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01, 10.68it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:00, 10.07it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:00<00:00,  9.90it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.69it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.71it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.70it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.51it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.54it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.045111123472452164, 'eval_mean_iou': 0.847790939268144, 'eval_mean_accuracy': 0.8956168035994622, 'eval_overall_accuracy': 0.981742913382394, 'eval_per_category_iou': [0.9808678338110964, 0.7147140447251915], 'eval_per_category_accuracy': [0.992888685149291, 0.7983449220496334], 'eval_runtime': 3.2514, 'eval_samples_per_second': 21.529, 'eval_steps_per_second': 5.536, 'epoch': 16.0}\n",
      " 80%|███████████████████████████████▏       | 5696/7120 [14:33<02:23,  9.94it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.54it/s]\u001b[A\n",
      "{'loss': 0.0286, 'grad_norm': 0.2140345573425293, 'learning_rate': 9.978932584269664e-06, 'epoch': 16.01}\n",
      "{'loss': 0.0281, 'grad_norm': 0.20373429358005524, 'learning_rate': 9.627808988764044e-06, 'epoch': 16.15}\n",
      "{'loss': 0.0322, 'grad_norm': 0.29010722041130066, 'learning_rate': 9.276685393258427e-06, 'epoch': 16.29}\n",
      "{'loss': 0.0224, 'grad_norm': 0.19837823510169983, 'learning_rate': 8.92556179775281e-06, 'epoch': 16.43}\n",
      "{'loss': 0.0277, 'grad_norm': 0.3339308798313141, 'learning_rate': 8.574438202247191e-06, 'epoch': 16.57}\n",
      "{'loss': 0.0284, 'grad_norm': 0.2191343903541565, 'learning_rate': 8.223314606741573e-06, 'epoch': 16.71}\n",
      "{'loss': 0.0266, 'grad_norm': 0.5497002601623535, 'learning_rate': 7.872191011235954e-06, 'epoch': 16.85}\n",
      "{'loss': 0.03, 'grad_norm': 0.4329378306865692, 'learning_rate': 7.521067415730337e-06, 'epoch': 16.99}\n",
      " 85%|█████████████████████████████████▏     | 6052/7120 [15:24<02:55,  6.09it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:02,  6.15it/s]\u001b[A\n",
      " 17%|███████▎                                    | 3/18 [00:00<00:02,  7.13it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 28%|████████████▏                               | 5/18 [00:00<00:02,  6.31it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01,  6.75it/s]\u001b[A\n",
      " 39%|█████████████████                           | 7/18 [00:01<00:01,  7.19it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:01<00:01,  6.64it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 9/18 [00:01<00:01,  7.13it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:01,  7.35it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  7.53it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  6.75it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  7.26it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  7.69it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:02<00:00,  7.94it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:02<00:00,  7.94it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04580775275826454, 'eval_mean_iou': 0.8463081839620858, 'eval_mean_accuracy': 0.8895273121111794, 'eval_overall_accuracy': 0.9817737579345703, 'eval_per_category_iou': [0.9809150545800577, 0.7117013133441141], 'eval_per_category_accuracy': [0.9937115760253474, 0.7853430481970114], 'eval_runtime': 4.3843, 'eval_samples_per_second': 15.966, 'eval_steps_per_second': 4.106, 'epoch': 17.0}\n",
      " 85%|█████████████████████████████████▏     | 6052/7120 [15:29<02:55,  6.09it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:04<00:00,  7.94it/s]\u001b[A\n",
      "{'loss': 0.0308, 'grad_norm': 0.24659688770771027, 'learning_rate': 7.16994382022472e-06, 'epoch': 17.13}\n",
      "{'loss': 0.0293, 'grad_norm': 0.42170900106430054, 'learning_rate': 6.818820224719101e-06, 'epoch': 17.28}\n",
      "{'loss': 0.0258, 'grad_norm': 0.24723131954669952, 'learning_rate': 6.467696629213484e-06, 'epoch': 17.42}\n",
      "{'loss': 0.0232, 'grad_norm': 0.1775827556848526, 'learning_rate': 6.116573033707865e-06, 'epoch': 17.56}\n",
      "{'loss': 0.0299, 'grad_norm': 0.15552809834480286, 'learning_rate': 5.765449438202248e-06, 'epoch': 17.7}\n",
      "{'loss': 0.0237, 'grad_norm': 0.2562541961669922, 'learning_rate': 5.41432584269663e-06, 'epoch': 17.84}\n",
      "{'loss': 0.0286, 'grad_norm': 0.1803237795829773, 'learning_rate': 5.063202247191011e-06, 'epoch': 17.98}\n",
      " 90%|███████████████████████████████████    | 6408/7120 [16:20<01:16,  9.26it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 18.54it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 10.93it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01,  9.98it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.53it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  9.39it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.37it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.38it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.37it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.30it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.44it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.49it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04463522508740425, 'eval_mean_iou': 0.8497424833789422, 'eval_mean_accuracy': 0.9003089939836477, 'eval_overall_accuracy': 0.981859370640346, 'eval_per_category_iou': [0.9809786127247562, 0.7185063540331282], 'eval_per_category_accuracy': [0.9924129865880638, 0.8082050013792317], 'eval_runtime': 3.4041, 'eval_samples_per_second': 20.563, 'eval_steps_per_second': 5.288, 'epoch': 18.0}\n",
      " 90%|███████████████████████████████████    | 6408/7120 [16:24<01:16,  9.26it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.49it/s]\u001b[A\n",
      "{'loss': 0.0274, 'grad_norm': 0.27794599533081055, 'learning_rate': 4.7120786516853936e-06, 'epoch': 18.12}\n",
      "{'loss': 0.0277, 'grad_norm': 0.3579849302768707, 'learning_rate': 4.360955056179775e-06, 'epoch': 18.26}\n",
      "{'loss': 0.0297, 'grad_norm': 0.19652649760246277, 'learning_rate': 4.009831460674157e-06, 'epoch': 18.4}\n",
      "{'loss': 0.0236, 'grad_norm': 0.09963536262512207, 'learning_rate': 3.6587078651685395e-06, 'epoch': 18.54}\n",
      "{'loss': 0.0289, 'grad_norm': 0.5494384169578552, 'learning_rate': 3.3075842696629213e-06, 'epoch': 18.68}\n",
      "{'loss': 0.0258, 'grad_norm': 0.19690567255020142, 'learning_rate': 2.956460674157303e-06, 'epoch': 18.82}\n",
      "{'loss': 0.0284, 'grad_norm': 0.2955702543258667, 'learning_rate': 2.6053370786516854e-06, 'epoch': 18.96}\n",
      " 95%|█████████████████████████████████████  | 6764/7120 [17:17<00:36,  9.72it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 17.98it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 10.29it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01,  9.88it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.65it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  9.53it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.49it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.41it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.39it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.03it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.15it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.23it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04507622495293617, 'eval_mean_iou': 0.849437285020582, 'eval_mean_accuracy': 0.8982799868598605, 'eval_overall_accuracy': 0.9818987165178571, 'eval_per_category_iou': [0.9810248446229205, 0.7178497254182434], 'eval_per_category_accuracy': [0.9927200026360256, 0.8038399710836955], 'eval_runtime': 3.1939, 'eval_samples_per_second': 21.917, 'eval_steps_per_second': 5.636, 'epoch': 19.0}\n",
      " 95%|█████████████████████████████████████  | 6764/7120 [17:20<00:36,  9.72it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:02<00:00,  9.23it/s]\u001b[A\n",
      "{'loss': 0.0253, 'grad_norm': 0.06193896383047104, 'learning_rate': 2.2542134831460673e-06, 'epoch': 19.1}\n",
      "{'loss': 0.0291, 'grad_norm': 0.08137334883213043, 'learning_rate': 1.9030898876404495e-06, 'epoch': 19.24}\n",
      "{'loss': 0.0276, 'grad_norm': 0.3612191379070282, 'learning_rate': 1.5519662921348316e-06, 'epoch': 19.38}\n",
      "{'loss': 0.0256, 'grad_norm': 0.16590410470962524, 'learning_rate': 1.2008426966292134e-06, 'epoch': 19.52}\n",
      "{'loss': 0.0269, 'grad_norm': 0.15951530635356903, 'learning_rate': 8.497191011235955e-07, 'epoch': 19.66}\n",
      "{'loss': 0.0273, 'grad_norm': 0.4578113555908203, 'learning_rate': 4.985955056179775e-07, 'epoch': 19.8}\n",
      "{'loss': 0.0298, 'grad_norm': 0.5816311240196228, 'learning_rate': 1.4747191011235956e-07, 'epoch': 19.94}\n",
      "100%|███████████████████████████████████████| 7120/7120 [18:11<00:00,  9.98it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|████▉                                       | 2/18 [00:00<00:00, 17.38it/s]\u001b[A\n",
      " 22%|█████████▊                                  | 4/18 [00:00<00:01, 11.29it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 6/18 [00:00<00:01,  9.97it/s]\u001b[A\n",
      " 44%|███████████████████▌                        | 8/18 [00:00<00:01,  9.59it/s]\u001b[A\n",
      " 56%|███████████████████████▉                   | 10/18 [00:01<00:00,  9.41it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 11/18 [00:01<00:00,  9.35it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 12/18 [00:01<00:00,  9.29it/s]\u001b[A\n",
      " 72%|███████████████████████████████            | 13/18 [00:01<00:00,  9.27it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 14/18 [00:01<00:00,  9.23it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 15/18 [00:01<00:00,  9.08it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 16/18 [00:01<00:00,  9.07it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/datasets/features/image.py:357: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 0.04510005936026573, 'eval_mean_iou': 0.8496107172048973, 'eval_mean_accuracy': 0.9001818913087243, 'eval_overall_accuracy': 0.9818429129464286, 'eval_per_category_iou': [0.9809616442706682, 0.7182597901391264], 'eval_per_category_accuracy': [0.9924108477076694, 0.8079529349097793], 'eval_runtime': 3.3662, 'eval_samples_per_second': 20.795, 'eval_steps_per_second': 5.347, 'epoch': 20.0}\n",
      "100%|███████████████████████████████████████| 7120/7120 [18:14<00:00,  9.98it/s]\n",
      "100%|███████████████████████████████████████████| 18/18 [00:03<00:00,  9.07it/s]\u001b[A\n",
      "{'train_runtime': 1095.361, 'train_samples_per_second': 25.964, 'train_steps_per_second': 6.5, 'train_loss': 0.04355160282568985, 'epoch': 20.0}\n",
      "100%|███████████████████████████████████████| 7120/7120 [18:15<00:00,  6.50it/s]\n",
      "✅ Saved to /workspace/segformer-lane/best\n"
     ]
    }
   ],
   "source": [
    "# 키 이름 패치: evaluation_strategy → eval_strategy (Transformers 5.x)\n",
    "!sed -i 's/evaluation_strategy/eval_strategy/g' /workspace/lane_seg/train_segformer.py\n",
    "\n",
    "# 학습 실행\n",
    "!python /workspace/lane_seg/train_segformer.py \\\n",
    "  --data_dir /workspace/ds_rf \\\n",
    "  --output_dir /workspace/segformer-lane \\\n",
    "  --epochs 20 --batch 4 --binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "525a0bb2-2d12-4963-8a63-48c0139d85be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KakaoTalk_20250707_100128756.mp4']\n"
     ]
    }
   ],
   "source": [
    "#이 셀을 실행하기 전에, 동영상을 먼저 업로드해야 이름을 확인해줌.\n",
    "import glob, os\n",
    "print([os.path.basename(p) for p in glob.glob(\"/workspace/*.mp4\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62f5852c-4375-40d4-8169-0aea89df07c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /workspace/out_lane_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "#내가 업로드한 input 동영상을 입력.\n",
    "!python /workspace/lane_seg/infer_segformer_video.py --model_dir /workspace/segformer-lane/best --input /workspace/KakaoTalk_20250707_100128756.mp4 --output /workspace/out_lane_overlay.mp4 --alpha 0.5 --device cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
